---
title: "Optimizing Bed Allocation in Stroke Units: A Simulation-Based Analysis"
number-sections: true
echo: FALSE
format: 
    pdf: 
      fig-pos: 'h'
bibliography: reference.bib
csl: academic-medicine.csl
---

### ***Abstract***:

#### **Introduction**: {#sec-introduction}

Geographical stroke units offer proven stroke therapy for ischemic and hemorrhagic stroke patients. Optimal care is achieved when patients are allocated to these wards. Access to stroke care units has been attributed to as one of the leading causes of declining death rates among stroke patients in Australia. Consequently, estimating the optimal number of beds required is a complex task. This study/project leverages discrete-event simulation (DES), grounded in queuing theory, to ascertain the ideal number of beds for optimal care given to patient influx. The study utilized stroke unit data including arrival rates, bed occupation times, and stroke severity probabilities to generate realistic scenarios for the simulation model. The objective of this project was to evaluate the impact of varying bed capacities on the performance of stroke care units such as bed utilization, maximum queue length, and percent of patients waiting.

#### **Method and Design**: {#sec-methods}

The simulation model considered factors such as patient arrival rates, stroke severity probabilities, and bed occupation times. Patient arrival rates were estimated to be 1 patients/day (on average), based on an annual patient load of \~350. The distribution of stroke severity was as follows:

-   very mild (probability = 0.0570),

-   mild (probability = 0.342),

-   mild-moderate (probability = 0.217),

-   moderate (probability = 0.136),

-   moderate-severe (probability = 0.0971) and

-   severe (probability = 0.151).

    Bed occupation times ranged from 1 day (very mild) to 4-10 days (severe). The study explored 5-50 bed scenarios and considered an increase in patient arrival to 2500 in the future. Simulation was run for $2000$ replications, evaluating performance measures (e.g., average queue length, maximum queue length, and capacity utilization) with an initial 7-bed provision.

In this project, data from 2021 on stroke patients at Monash hospital was utilized to estimate the number of stroke unit beds needed given the distribution of stroke severity and the length of stay associated with each category of stroke severity. Moreover, I have developed a web-based app such that policy makers and clinicians can use it as policy support tool to estimate the number of bed needed in their hospitals.

#### **Results:** {#sec-discussion}

A simulation model showed that the initial 7-bed provision was inadequate for the annual patient load of \~ $350$, leading to prolonged wait times and queues. The percent of patients queuing was around \~ $19 \%$ for 7 beds, $15\%$ for 8 beds, \~ $8\%$ for 9 beds and \~ $5\%$ for 10 beds.

### ***Background and Motivation***

#### **Introduction to hospital capacity planning**

Across the world healthcare systems are under continual pressure to provide accessible and effective health services to patients as the size of population continues to grow; consequently, the decision-making regarding the adequate provision of services to the patients is crucial for optimal patient care in hospitals. Hence, hospital capacity planning has emerged as a critical issue due to the increasing demand for hospital care and rising costs of inpatient care.

Key metrics, such as bed capacity and associated indices such as bed occupancy and the ratio of beds to population are used to determine the availability of inpatient care [@Ravaghi2020].

Under-utilization of beds in the hospitals lead to additional costs, while on the other hand, a shortage of available beds is the primary cause of delays in emergency admission, surgery cancellations, and premature patient discharge [@rechel2010hospital].

According to Storey et al. (2010) in their article "Hospital capacity planning: From measuring stocks to modelling flows" published in the Medical Journal of Australia, an 85% bed occupancy rate is a reasonable target for hospitals. However, this target may need adjustment depending on the facility and time periods @martin_storey_2010.

#### Prevalence of stroke in Australia and Victoria

Stroke is ranked as the second leading cause of death with an annual mortality rate of over $6.5$ million worldwide and $143.23$ million disability-adjusted life years (DALYs) in 2019 according to the *Global stroke fact sheet* released by the [World Stroke Organization](https://www.world-stroke.org/news-and-blog/news/wso-global-stroke-fact-sheet-2022).

In Australia in 2020 an estimated $445,087$ [^1]Australians aged 15 and over were grappling with the aftermath of stroke. In 2018, $1.3\%$ of the Australian population had experienced a stroke at *some point* in their lives, based on self-reported data from the [ABS Survey of Disability, Ageing and Carers (ABS 2019)](https://www.aihw.gov.au/reports/heart-stroke-vascular-diseases/hsvd-facts/contents/heart-stroke-and-vascular-disease-subtypes/stroke). As per the same source, in 2020, there were an estimated $39,500$ **stroke events** in Australia--- more than $100$ everyday. The rate of stroke events was $154$ per $100,000$ population. These stroke events include the new and recurrent stroke.[^2]

[^1]: According to the Economic Impact of Stroke (Deloitte Australia - 2020) [The report can be found here.](https://www2.deloitte.com/au/en/pages/economics/articles/economic-impact-stroke-australia.html)

[^2]: There are no direct national data sources on the annual number of strokes. However, a related measure can be used as an estimate---the number of stroke events---developed by the AIHW using unlinked hospital and deaths data (AIHW 2022)

In 2020, stroke was recorded as the underlying cause of $8,200$ deaths, accounting for $5.1\%$ of all deaths in Australia. Stroke was one of the $5$ leading causes of death in Australia -- on average, $22$ Australians died of stroke each day in 2020.[^3]

[^3]: These figures were obtained from the [Australian Institute of Health & Welfare (AIHW)](https://www.aihw.gov.au/reports/heart-stroke-vascular-diseases/hsvd-facts/contents/summary-of-coronary-heart-disease-and-stroke/stroke)

Since 1980 the death rates for stroke have fallen by three-quarters -- from *110 to 23* per **100,000** population for males, and from *99 to 24* per **100,000** population for females. Access to stroke care units has been attributed to as one of the leading factors for declining death rates in Australia[^4]. Hence adequate access to the stroke care is crucial for the recovery and rehabilitation of the stroke patients as well as in reducing the stroke-related death rates.

[^4]: See 'Chapter 4 Changing patterns of mortality in Australia since 1900' in [*Australia's health 2022: data insight*](https://www.aihw.gov.au/reports/australias-health/australias-health-2022-data-insights).

While, according to the *Victorian Population Health Survey* (2016) [^5], the prevalence of stroke among the adult Victorian population was 2.7%, and in Melbourne, the incidence and prevalence of stroke follow similar trends observed across Australia.

[^5]: 2.7% of the adult Victorian Population self-reported doctor diagnosed stroke [in the survey](https://www.health.vic.gov.au/population-health-systems/victorian-population-health-survey-2016).

The growing population and aging demographic contribute to the increasing demand for stroke care in the region. According to the Australian Institute of Health and Welfare, the age-standardized prevalence of stroke in Melbourne has been on the rise, highlighting the need for better access to specialized care for stroke patients.

#### Access to Beds in Stroke Care Units

In a recent international survey, stroke unit care was only available in $91\%$ of High-Income countries @owolabi2021state . With an increasing availability of stroke unit, there is decrease in social inequality of access to stroke unit care in Sweden @glader2013reduced while in North America access to stroke care units remains an issue @yu2021demographic .

In Australia, $81\%$ of hospitals have stroke care units @foundation2021audit . An important issue in access to the stroke unit bed is the capacity of the hospital with stroke unit care to provide the service. A national survey in 2021 showed that $71\%$ of patients were treated in stroke unit while $29\%$ of the patients from the same hospitals were not treated in such location @foundation2021audit . The Stroke Foundation has set a target of $94\%$ access to stroke unit. A related document suggested a minimum of 8 bed for a unit with $350$ admitted patients and $22$ beds for a unit with more than 1000 admitted patients @foundation2019framework .

#### Monash Hospital {#sec-mmri}

In the stroke ward at the Monash Hospital there are a total of 46 beds as used by the neurology, neurosurgery and stroke patients. The objective of this project was to estimate the optimal number of beds specifically for the stroke patients at the Monash Hospital to ensure the optimum care for the stroke patients.

For the purpose of this project at the *Monash Medical Research institute*, I used the **simulation modelling** grounded in queue theory to represent a queuing system within a hospital setting.

### *Objectives and Significance*

#### **Objectives** {#sec-objectives}

The primary objective of this project was to develop *discrete event simulation* (DES) model that accurately captures the dynamics of the stroke ward at the Monash hospital. The main objective of DES was to simulate the flow of patients as they arrive, wait in line (queue) for an available bed, receive treatment, and exit the resource (making the bed available for the next patient in the queue to use).

In order to achieve these objectives an evaluation of different bed capacities on three key performance metrics were considered:

-   Maximum queue length of the given annual load of stroke patients;
-   the percent of the patients waiting to be admitted into the ward and;
-   the utilization rates/percentages

Further, this model is intended to be used as a decision support tool by the hospital administrators and policymakers in optimizing bed allocation at the stroke ward.

#### **Significance and Contributions**: {#sec-significanceContribution}

In this project, *Discrete Event Simulation* grounded in queue theory accurately captures the complexity and inherent variability of a stroke ward. This model takes into account the stochastic nature of the patient arrivals, stroke severity levels, and length of stay. This enables a comprehensive analysis of the hospital ward's performance under different scenarios.

By effectively representing the complex interaction between different factors such as the patients arrival, stoke categories, stroke level probabilities and bed occupation times for each of the different categories of stroke, this DES model is meant to provide valuable insights into the stroke ward's operations at the Monash Hospital.

Furthermore, this model enables users to generate performance metrics, such as the percent of patients waiting and utilization percentages for the given number of beds and load of patients in the stroke ward.

#### **Novel Features:** {#novelFeatures}

While simulation modeling in healthcare is not a novel concept, this project aims to broaden the accessibility of the simulation modelling developed as part of this project by making it available as a support tool to a wider audience through a user-friendly shiny web-app which can be accessed [here.](https://aryan-sultan-1120.shinyapps.io/App_for_stroke_simulation/) (https://aryan-sultan-1120.shinyapps.io/App_for_stroke_simulation/).

The Shiny app enables users to interactively adjust the number of patients, beds as well as the length of stay (bed occupation times) for each different categories of the stroke using slider inputs, which allows users to visualize a plot of the percentage of patients waiting to be admitted into the ward based on the selected number of patients and beds. In addition the users can also view a plot of the utilization rates at the selected number of beds. Furthermore, the users are able to see the optimal number of beds for the selected patient load. By offering this tool in a web-based format, a wider audience can benefit from the insights generated by our simulation model, thereby enhancing decision-making processes in healthcare settings.

### *Methodology*

The methodology employed in this analysis is based on Discrete Event Simulation (DES), a widely recognized and effective technique for modeling complex systems with stochastic elements. Discrete Event Simulation (DES) is a computer-based modeling technique that simulates the operation of a system as a sequence of discrete events in time. Each event represents a change in the system's state.

#### **Discrete Event Simulation (DES)** {#sec-des}

Discrete Event Simulation (DES) is a computer-based modeling technique that simulates the operation of a system as a sequence of discrete events in time. Each event represents a change in the system's state. @Robinson2004

DES offers several advantages over traditional analytic methods.

-   DES can model a variety of systems, including those with the stochastic and dynamic elements that may otherwise prove difficult to be analyzed when using traditional methods such as a deterministic queuing models.

For example the DES model for stroke ward incorporates various stochastic and dynamic elements, such as patient arrivals, stroke severity levels, and length of stay. These elements are inherently unpredictable and can change over time. On the other hand, the traditional analytic methods, such as deterministic queuing models, may not fully capture the randomness and variation in these components.

-   Secondly, the DES represents the individual components and their interaction in the system.

For example our DES simulation model in this study consists of multiple components, including patients, and beds. Each of these components interacts with one another in a complex way, as patients move through the ward, occupy and utilize bed resource. Traditional analytic methods might simplify these interactions or aggregate them, potentially losing critical information about the system's behavior.

-   Furthermore, one of the key advantages of the DES is the flexibility. DES model allows for changes in the system's behavior to be successfully incorporated into the model, and even test for various scenarios and interventions.

For example in stroke simulation model, the ***changes*** in patient population (inflow), their length of stay and stroke level probabilities associated with the stroke categories can be accounted for easily and reliably.

In light of these advantages, DES simulation was an appropriate choice for modelling the dynamics of the stroke ward in this project. @jacobson2006discrete

#### Data {#sec-data}

The data used in this project is derived from multiple sources including historical records (2021) and hospital statistics; furthermore, valuable insights regarding the patient arrivals, annual patient load and the bed occupation times for different categories of stroke were obtained from the supervisor for this project, Professor Thanh Phan, Head of Neuroscience Research, Monash Health.

It is important to note that simulation model as a method presents certain limitations.

-   One of the key limitations of the simulation model is the validation and calibration of simulation model is a challenging process and can be quite time consuming at times.

-   One of the other challenges I faced was that the computation times were long. DES can be computationally intensive when running multiple thousand simulation or under multiple scenarios.

To counter these limitations, we used the relevant data from 2021 records of the stroke patients in the hospital, and most importantly, the critical information on patient's length of stay (bed occupation times), stroke category probabilities were supplied by the supervisor for this project at Monash Health, Professor Thanh Phan. However, in this simulation model I have run $2000$ simulations to attain the results. This process was time consuming and computationally intensive, but produced reliable results.

#### Method {#sec-method}

In order to develop this model several auxiliary functions were created to :

-   generate the patient inter-arrival times,

-   assign stroke categories to incoming patients in the simulation (based on the stroke level probabilities),

-   generate their length of stay (based on the stroke category they were assigned),

To simulate the patient inflow, stay and exit, and compute certain performance metrics such as the percent of the patients waiting, utilization rates and maximum queue length, two main functions were created:

-   `stroke_simulation()` function which updated the bed occupation times, kept track of the waiting patients in the queue and finally assigned the beds to the patients waiting in the queue.

-   `run_simulation()` computed the performance metrics and ran the simulation for 2000 times.

#### Key parameters

The stroke categories were assigned based on the stroke level probabilities. The total annual patient load considered for this analysis was \~ $350$. The performance metrics were computed for $350$ yearly patients as well as for the an estimated annual load of 2500 patients.

The following parameters were used to lay the foundation for the stroke simulation model. These parameters were obtained from the historical data of the stroke ward.

-   Total annual patients: 350

-   Arrival rate: $\frac {350} {365} =\ 0.958\ \sim 1$ patient per day on average -- this means on average one patients arriving into the ward each day.

-   Stroke level probabilities & bed occupation times see Table 1:

```{r echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE}

#| label: tbl-strokeCat
#| tbl-cap: Stroke Categories, Probabiliy and Bed Occupation times

library(tidyverse)
library(ggplot2)
library(bookdown)

set.seed(07052023)
# Parameters

total_patients <- 350 # assuming there are 350 all around the year
total_patients_future <- 1250 # assuming the 2500 patients in the future 
patients_per_month <- 350/12 # patients per month
arrival_rate <- total_patients/365  # average 6 patients per day
arrival_rate_future <- total_patients_future/365 # average 7 patients per day

# Bed occupation time (in days) for each stroke level

bed_occupation_time <- list(c(4.43), c(4.46), c(6.67), c(6.92), c(7.74), c(9.29))


# Probability of each stroke level
stroke_level_prob <- c(0.0570,0.342, 0.217, 0.136, 0.0971, 0.151)

# visualization

library(ggplot2)

bed_occupation_time_df <- data.frame(
  stroke_category = c("Very Mild", "Mild", "Mild-Moderate", "Moderate", "Moderate-Severe", "Severe"),
  bed_occupation_time = c(4.43,4.46,6.67,6.92,7.74,9.29),
  probability = c(0.0570,0.342, 0.217, 0.136, 0.0971, 0.151)
)

updated_bed_occupation_time_df <- bed_occupation_time_df

colnames(updated_bed_occupation_time_df) <- c("Stroke Categories", "Bed Occupation times", "Stroke Probability")

updated_bed_occupation_time_df %>%
  knitr::kable(caption = "Stroke categories and corresponding length of stay and probabilities")
```

See Figure:1 for the summary of the stroke categories and the associated probabilities with corresponding length of stay.

```{r figcat, fig.cap="Stroke categories, probabilities and bed occupation times", fig.align= 'center', fig.height=4, fig.width= 6, eval=TRUE}

# viz for the stroke categrories.

v1 <-ggplot(updated_bed_occupation_time_df, aes(x = `Stroke Categories`, y = `Bed Occupation times`)) +
  geom_col(fill = "steelblue") +
  theme_minimal()+
  geom_text(aes(label = scales::percent(`Stroke Probability`, accuracy = 0.1)), 
            position = position_stack(vjust = 0.5), color = "white", size = 4) +
  theme_minimal() +
  labs(
       x = "Stroke Category",
       y = "Bed Occupation Time (days)")
v1

```

With these input parameters, the stroke simulation model was developed to achieve the results; auxiliary functions that generated the inter-arrival times, assigned stroke categories to the patients in the simulation, and generated the bed occupation times for the patients based on their stroke categories were used in the stroke simulation function.

Please refer to the flow chart below to understand the work flow for this model.

```{r}
knitr::include_graphics("flowchart.png")
```

\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--

#### Inter-arrival times {#sec-iat}

In specifying a queuing model, we make assumptions about the probabilistic nature of the arrival and service processes. The most common assumption to make about arrivals is that they follow a *Poisson process. @green2011queueing*

Assume $N_t$ is the number of arrivals during a time period of duration $t$ and $N_t$ has a Poisson distribution, then:

Probability Mass Function of the Poisson is given as = $$\{N_t = n\} = \frac {e-λt
 (λt)n} {n!} $$ where $\lambda$ is called the *rate* and is the expected number of arrivals per unit time. Another way to characterize this Poisson process is that the time between consecutive arrivals, called the *inter-arrival time*, which has an exponential distribution.

Mathematically, the inter-arrival time for our model was generated in the following way:

-   Total number of patients = $350$, hence let $n=350$

-   Arrival rate = 1 patient per day on average, therefore, $\lambda =1$

    The exponential distribution has a probability density function (PDF) given by:

    $$f(T) = λ \times Exp(-λ(T))$$

    where $\lambda$ is the arrival_rate, and $T$ is a random variable representing the time between two successive patient arrivals.

    In the simulation for each patient "$i$" in the 350 patients (total number of patients), we generate an inter-arrival time $T_i$ from an exponential distribution with the rate $(\lambda)$:

    $$T_i \sim Exp(1)$$

    This generates a sequence of inter-arrival times: $T_1, T_2, T_3,… T_{350}$ that is exponentially distributed with $\lambda$ = $1$.

```{r echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE}

# total patients = 350
# arrival rate = 6

generate_interarrival_times <- function(total_patients, arrival_rate) {
  set.seed(07052023)
  interarrival_times <- rexp(total_patients, rate = arrival_rate)
  return(interarrival_times)
}

```

This function generates the inter-arrival time of the patients.

#### Assigning the stroke categories to Patients {#sec-assign}

Next, I created a `assigning_stroke_levels` function to assigns stroke categories to patients.

The `assign_stroke_levels` function assigns stroke categories to patients based on a given set of probabilities for each category. These probabilities have been mentioned earlier in the report, please refer to Table 1.

This function takes two arguments:

1\. `total_patients`: The total number of patients for which stroke categories will be assigned.

2\. `stroke_level_prob`: A vector containing the probability of each stroke category.

Mathematically, this process can be explained as follows:

Let $Y_1, Y_2, ..., Y_n$ be the stroke categories for $n$ patients, where $n =350$. Each $Y_i$ is an independent random variable, meaning the stroke category assigned to one patient does not influence the category assigned to another patient. Each $Y_i$ represents the stroke category for $i^{th}$ patient. It takes values from $1 \to k$, where $k=6$ as there are six stroke categories. The probability of $Y_i$ taking the value $j$ stroke category where $j$ ranges from $(1 ≤ j ≤ 6)$ is given by:

$P(Y_i = j) = p_j$

where $p_j$ is the probability of the $j^{th}$ stroke category, specified in the `stroke_level_prob` vector.

Then in this R-function stroke categories are assigned to patients by sampling from a discrete probability distribution with the specified probabilities:

$Y_1, Y_2, ..., Y_n$ = sample( $1:k$ , size = $n$ , replace = TRUE, prob = $p$)

The `replace = TRUE` argument ensures that each patient's stroke category is assigned independently, allowing for repeated selections of the same category.

```{r eval=TRUE, echo=FALSE}

# stroke_level_prob <- c(0.0570,0.342, 0.217, 0.136, 0.0971, 0.151)

assign_stroke_levels <- function(total_patients, stroke_level_prob) {
  set.seed(07052023)
  stroke_levels <- sample(1:length(stroke_level_prob), 
                          size = total_patients, 
                          replace = TRUE, 
                          prob = stroke_level_prob)
  return(stroke_levels)
}

stroke_levels <- assign_stroke_levels(total_patients, stroke_level_prob)
```

#### Generating the Length of Stay {#sec-los}

As discussed (refer to Table 1), the bed occupation times for each category are defined -- please note that these were the bed occupation times used in this analysis, as a policy support tool, this model allows professionals to change the bed occupation times for patients as suitable for their analysis, moreover, the shiny-web-app developed for this project allows users to select different bed occupation times for different categories of the stroke.

For this simulation model once the inter-arrival times and the stroke categories to the arriving patients have been assigned, the next step was to generate the length of stay of these patients based on their stroke level/category.

Length of stay for patients was based on the stroke category they were assigned by the `assign_stroke_levels` function. This function takes three arguments:

-   total number of patients,

-   bed occupation times, and

-   the stroke categories (stroke levels). Stroke levels/categories are defined by the previous function - `assign_stroke_levels` function as described earlier.

```{r eval=TRUE, echo=FALSE}

generate_length_of_stay <- function(total_patients, bed_occupation_time, stroke_levels) {
  set.seed(07052023)
  los <- numeric(total_patients)

  i <- 1
  while (i <= total_patients) {
    set.seed(07052023)
    stroke_categories <- stroke_levels[i]
    bed_time <- bed_occupation_time[[stroke_categories]]
    los[i] <- if (length(bed_time) == 1) {
      bed_time[1]
    } else {
      set.seed(07052023)
      sample(bed_time[1]:bed_time[2], 1)
    }
    i <- i + 1
  }

  return(los)
}



# Generating length_of_stay for each patient
length_of_stay <- generate_length_of_stay(total_patients, 
                                          bed_occupation_time, 
                                          stroke_levels)
```

#### Arrivals data {#sec-arrivalData}

Having defined these functions, the next step was to check the distribution of the length of stay of patients in our simulation model and have a look at the patients arrival data.

```{r echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE}
set.seed(07052023)

# generating the arrival data for the current volume of patients

# Add number_of_patients and length_of_stay to arrivals_data

interarrival_times <- generate_interarrival_times(total_patients, arrival_rate)

stroke_levels <- assign_stroke_levels(total_patients, stroke_level_prob)

length_of_stay<- generate_length_of_stay(total_patients, bed_occupation_time, stroke_levels)

arrivals_data <- data.frame(interarrival_times, stroke_levels, length_of_stay)

```

```{r eval=TRUE, echo=FALSE, warning=FALSE}
arrivals_data$stroke_categories <- factor(arrivals_data$stroke_levels,
                                          levels = c(1, 2, 3, 4, 5, 6),
                                          labels = c("Very Mild", "Mild", "Mild-Moderate", "Moderate", "Moderate-Severe", "Severe"))

colnames(arrivals_data) <- c("Interarrival times", "stroke levels", "Length of stay", "stroke categoryNames")

arrivals_data %>% 
  select(-`stroke levels`) %>%
  head() %>%
  knitr::kable(caption = "Patient Arrival Data")
```

This table (Table: 2) shows us just the first six rows of the actual data I created with the three functions mentioned earlier. In the table we can see that the inter-arrival times of the patients, stroke categories these patients were assigned and their length of stay in the ward.

We can further examine the distribution of the **mean** length of stay of patients in the arrivals data. (refer to Figure: 2)

```{r figtwo, fig.cap="Patients Arrival Data", fig.align= 'center', fig.height=4, fig.width= 6, eval=TRUE, fig.pos="H"}
ggplot(arrivals_data, aes(x = `stroke categoryNames`, y = `Length of stay`, fill = `stroke categoryNames`)) +
  geom_bar(stat = "summary", fun = "mean", position = "dodge") +
  geom_text(aes(label = round(`Length of stay`, 1)), vjust = 1, size = 4) +
  theme_minimal() +
  scale_y_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10))+
  labs(title = "Mean Length of Stay by Stroke Category",
       x = "Stroke Category",
       y = "Mean Length of Stay (days)") +
  scale_fill_discrete(name = "Stroke Category")+
        theme(axis.text.x = element_text(angle = 45 ,hjust = 1),
            legend.position = "none")
```

In Figure: 2 one can see the mean length of the patients' stay in the stoke ward against the stroke categories/levels. This figure shows us that in the arrivals data the patients that were assigned the *severe* category of stroke stayed the longest in the ward on average staying more than 9 days. One can examine the distribution of patients in each of the stroke category from the figure.

In Figure 3, the distribution of the patients in each category follows the stroke category probabilities and the highest number of patients -- 112 -- were assigned to the *mild* category of stroke --refer to Table 1 for information on the categories and the respective probabilities.

```{r echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, fig.align='center', fig.cap="Distribution of the stroke patients", fig.width=6, fig.height=5, fig.pos="H"}

library(dplyr)
arrivals_summary <- arrivals_data %>%
  count(`stroke categoryNames`) %>%
  mutate(max_count = n == max(n))

stroke_distribution <- ggplot(arrivals_summary, aes(x = `stroke categoryNames`, y = n, fill = max_count)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = n), vjust = -0.5, size = 4) +
  scale_fill_manual(values = c("darkgray", "steelblue"), guide = FALSE) +
  theme_minimal() +
  labs(
    x = "Stroke Category",
    y = "Number of Patients",
    title = "Distribution of Patients in Each Stroke Category"
  )

stroke_distribution



```

#### Stroke Simulation Function {#sec-ssf}

```{r echo=FALSE, eval=TRUE}
set.seed(07052023)

stroke_simulation <- function(total_patients, arrival_rate, 
                              bed_occupation_time, stroke_level_prob, 
                              num_beds) {
  set.seed(07052023)
  
  interarrival_times <- generate_interarrival_times(total_patients, arrival_rate)
  stroke_levels <- assign_stroke_levels(total_patients, stroke_level_prob)
  length_of_stay <- generate_length_of_stay(total_patients, bed_occupation_time, stroke_levels)
  
  # initializing the beds and queue 
  beds <- numeric(num_beds)
  queue <- list()
  

# inter-arrival_time is an input parameter for this function, 
# which represents the time between patient arrivals. 
# This variable is based on the generate_interarrival_times function, 
# where we input the total number of patients and arrival rate.

# The pmax function ensures that the bed occupation times do not become negative. 
# A value of 0 in this context means that the bed is available 
# (i.e., the patient has completed their stay)
  
  update_bed_occupation_times <- function(beds, interarrival_time) {
    set.seed(07052023)
  beds <- pmax(beds - interarrival_time, 0)
  
  # 'beds' is a numeric vector that represents the current remaining 
  # bed occupation time for each bed in the simulation.
  # Each element in this vector corresponds to a bed in the hospital
  # ward. A value of 0 means that the bed is available for use.
  # Subtracting the inter-arrival_time from each element of 'beds' 
  # updates the remaining bed occupation times, considering the 
  # passage of time between patient arrivals.
  # The pmax function is used to ensure that the resulting bed 
  # occupation times do not become negative, meaning that a 
  # bed with a remaining time less than or equal to the interarrival_time
  # will be considered available (set to 0).
  return(beds)
}
  
  # for every patient in total patients (1000)
  
  i<- 1
  while(i <= total_patients) {
    set.seed(07052023)
    
    # update the beds variable with the bed occupation times 
    # of all the patients arriving at the inter-arrival times
    
    beds <- update_bed_occupation_times(beds, interarrival_times[i])
    # creating a new variable available beds to keep track 
    # of the available beds the beds that are available will
    # have the bed occupation time of 0 so in this variable 
    # I store the beds that are available hence which(beds==0)
    
    available_beds <- which(beds == 0)
    
    # here if the length of the available beds vector 
    # is greater than 0 which means that 
    # there is at least one bed with bed occupation times ==0 
    # then assign the first available bed to the patient 
    # by setting this available bed (bed occupation times ==0) 
    # to the length of the stay of the patient 
    # (whatever the severity of that patient might be)
    
    if (length(available_beds) > 0) {
      set.seed(07052023)
      beds[available_beds[1]] <- length_of_stay[i]
    } else {
      set.seed(07052023)
      # if there is no bed available then append the queue list
      queue <- append(queue, length_of_stay[i])
    }
    
    i <- i +1 
  }
  
  return(list(beds = beds, queue = queue, length_of_stay =length_of_stay))
}
```

In order to simulate the patient inflow, stay and discharge I created the `stroke_simulation` function, which uses the previously created functions to achieve the intended results.[^6]

[^6]: I acknowledge the use of \[1\] ChatGPT (<https://chat.openai.com/>) to \[2\] re-structure my stroke simulation code so that modularity in the code and the intended results could be acheived. I entered the following prompts in April 2023:

    -   \[3\] I have created the following code \[code for update_bed_occupation_times which is used inside the stroke simulation function\]. In this function I am subtracting the inter-arrival time from beds (numeric vector of length of number of beds) but I do not want this to give me negative values, I would like to be zero twhen the subtraction results in negative values.

    -   Now that I have created the update_bed_occupation_time function \[code\] and have created the list of the available beds using \[beds \<- update_bed_occupation_times(beds, interarrival_times)\], and I have also created a vector of available beds using \[available_beds \<- which(beds == 0)\] in a while loop, now how can I assign the bed as well as set the bed equal to the length of patient to whom the bed is assigned \[the entire code\].

    -   I have created the while loop \[code\] to do this but it does not achieve the result as I have explained. How can I set the bed equal to the length of stay of patient? I want the bed to be the remaining time of the bed occupation time of the patient. check my \[code\]

    -   there was some back forth dialogue to make sure that I got the intended results which was to set the bed equal to the length of stay of the assigned patient.

    \[4\] The output from the generative artificial intelligence was adapted and modified for the final response.

*Simulation Process*

The `stroke_simulation` function simulates the arrival of `total_patients` at a stroke ward with a limited number of beds (`num_beds`). The inter-arrival times of the patients, their length of stay in the ward, and their stroke categories are used inside the function to begin the simulation process.

For each arriving patient, this function first updates the bed occupation times for all beds, taking into account the time that has passed since the last patient arrival. This function keeps track of the available beds, and checks if there are any available beds. Vacant beds are assigned to the patients in case of the bed availability, else the patients are added to the queue, if all the beds are in use by other patients.

*Bed availability and queue*:

The primary challenge in the simulation is often to manage bed availability and the patient queue efficiently. Mathematically, the process of bed occupation times update can be described as follows:

For each arriving patient, the remaining bed occupation time for all beds is updated by subtracting the inter-arrival time since the last patient's arrival. If the remaining time becomes negative, it is set to 0 (the `pmax()` function achieves this), indicating that the bed is available.

Mathematically, the updated bed occupation time can be represented as:

$Tnew_i = max(T_i - t_{interarrival}, 0)$

where $Tnew_i$ is the new bed occupation time for bed $i$, $T_i$ is the previous bed occupation time for bed $i$, and $t_{interarrival}$ is the time between the current and previous patient arrivals.

If there's at least one available bed (bed occupation time = 0), the first available bed is assigned to the patient in the queue. The bed's occupation time is updated to the length of stay for the patient.

Mathematically, the assignment can be expressed as:

$Tnew_i$ = length_of_stay

where $Tnew_i$ is the updated bed occupation time for the first available bed $i$ and `length_of_stay` is the length of stay for the current patient.

If there are no available beds, the patient is added to the *queue*. The queue stores the length of stay for each patient in the order they arrive, and it represents the patients waiting for a bed to become available.

In summary, the mathematics behind the `stroke_simulation` function involves generating inter-arrival times, length of stay, and assigning stroke categories, as well as efficiently managing bed availability and patient queue dynamics using the concepts of bed occupation time updates, bed assignment, and patient queuing.

#### Running the simulation and computing performance metrics {#sec-runsim}

It is important to run the simulation multiple times to obtain more reliable results. This is to ensure that the results generated from this model are not due to random chance. Each simulation run produces different results due to the inherent randomness in the model. Averaging the outcomes over the several runs produces more stable estimates of the true expected values.

Hence `run_simulation` function[^7] was created in the process of simulation to run multiple simulations and compute the performance metrics such as the utilization rates and the percent of patients waiting and others for **different** number of beds -- I have defined a range of beds in the function to run simulations for range of beds (5 to 50) and compute the performance metrics for these range of beds in each individual simulation and then averaged the performance metrics across these simulations.

[^7]: I acknowledge the use of \[1\] ChatGPT (<https://chat.openai.com/>) to \[2\]

    -   \[3\] Write a 50 word summary about the formation of Monash University. Write it in an academic style. Add references and quotations from Sir John Monash.

    \[4\] The output from the generative artificial intelligence was adapted and modified for the final response.

In this `run_simulation` function, I essentially implement a *Monte Carlo* simulation, which is a mathematical technique that allows us to account for risk in quantitative analysis and decision making. Monte Carlo simulation calculates results over and over, each time using a different set of random values from the probability functions.

```{r echo=FALSE, eval=TRUE}
run_simulation <- function(arrival_rate,
                           bed_occupation_time,
                           stroke_level_prob,
                           total_patients,
                           num_simulations) {
  set.seed(07052023)
    num_bed_range <- seq(5,50, by=1)

  performance_metrics_list <- lapply(1:num_simulations, function(simulation) {
    set.seed(07052023)
    lapply(num_bed_range, function(num_beds) {
      set.seed(07052023)
      stroke_sim <- stroke_simulation(total_patients =  total_patients,
                                      arrival_rate = arrival_rate,
                                      bed_occupation_time = bed_occupation_time,
                                      stroke_level_prob = stroke_level_prob,
                                      num_beds = num_beds)

      num_beds <- length(stroke_sim$beds)
      total_patients <- total_patients

      occupied_beds <- sum(stroke_sim$beds > 0)
      utilization <- (occupied_beds / num_beds)*100

      total_wait_times <- sum(unlist(stroke_sim$queue))
      num_patients_queue <- length(stroke_sim$queue)
      avg_wait_times <- total_wait_times / num_patients_queue

      average_time_in_queue = total_wait_times / num_patients_queue
      max_queue_length <- length(stroke_sim$queue)

      proportion_patients_waiting <- num_patients_queue / total_patients
      percent_patients_waiting <- proportion_patients_waiting * 100

      avg_length_of_stay <- (sum(stroke_sim$length_of_stay)) / total_patients

      performance_metrics_month <- data.frame(num_beds = num_beds,
                                              utilization = utilization,
                                              avg_wait_times = avg_wait_times,
                                              max_queue_length = max_queue_length,
                                              # min_queue_length = stroke_sim$min_queue_length,
                                              proportion_patients_waiting = proportion_patients_waiting,
                                              percent_patients_waiting = percent_patients_waiting,
                                              avg_length_of_stay = avg_length_of_stay)

      return(performance_metrics_month)
    })
  })

  return(performance_metrics_list)
}

```

The function `run_simulation` takes five arguments: `arrival_rate`, `bed_occupation_time`, `stroke_level_prob`, `total_patients`, and `num_simulations`. (For detail on these arguments please see @sec-method )

This function first generated a sequence of numbers from $5- 50$ -- the range as I defined inside the function -- which represents the range of number of beds to be simulated. For each simulation and number of beds, the `stroke_simulation` function was run with the given parameters to simulate the scenario of a stroke ward with a specific number of beds and a certain number of patients. Various performance metrics were also calculated based on the output of the `stroke_simulation` function.

These performance metrics were then stored in a data frame for each number of beds and each simulation, and returned as a list of lists. In essence, for each simulation, the code ran the **stroke_simulation** function for each specified number of beds. This means that if there were $2000$ simulations and $45$ different numbers of beds (from 5 to 50), the `run_simulation` function ran a total of $90,000$ times $(2000 \times 45)$, each time with a different combination of simulation number and number of beds. The results of each of these simulations were collected into a list of data frames, which were then combined into a single data frame for further processing.

#### Results

In this section I will discuss the results from my simulation by visualizing the results.

The two key metrics that Prof. Phan, supervisor for this project, emphasized on reading for understanding the bed capacity needs of the stroke ward were the `percent of patients waiting` and the `utilization rates`. As explained by Prof. Phan, ideally the hospital would desire to have **less than 5%** of the patients waiting (queuing) to be admitted into the stroke ward at any given time. This is an important threshold considered when determining the optimal number of beds in the stroke ward.

Table 3 displays the key performance metrics for $350$ patients: percent of the patients waiting, utilization of beds (in $%$ $\%$ ) and the maximum queue length.

```{r echo=FALSE, eval=TRUE, warning=FALSE, message=FALSE}

set.seed(070523)

results <- run_simulation(arrival_rate = arrival_rate,
                          bed_occupation_time = bed_occupation_time,
                          stroke_level_prob = stroke_level_prob,
                          total_patients = total_patients,
                          num_simulations = 2000)

results_df <-do.call(rbind, lapply(results, function(x) do.call(rbind, x)))
results_df$percent_patients_waiting <- round(results_df$percent_patients_waiting)
results_df$utilization <- round(results_df$utilization)
results_df$avg_wait_times <- tidyr::replace_na(results_df$avg_wait_times, 0)

library(kableExtra)

results_df_table <- results_df %>%
  select(-proportion_patients_waiting,
         -avg_length_of_stay,
         -avg_wait_times) %>%
  rename(c(`Num. of beds`=num_beds,
           `Max. Queue Length`=max_queue_length,
            `Percent of Patients waiting` = percent_patients_waiting
    )) %>%
  head(10) %>%
  kableExtra::kbl(caption = "Table displaying the key performance metrics from the simulation")

results_df_table

```

```{r figfour, fig.cap="Percent of patients waiting vs the Number of beds", fig.align= 'center', fig.height=4, fig.width= 6, eval=TRUE, message=FALSE, warning=FALSE}

# Load the ggplot2 library
library(ggplot2)

# Plot the percent of patients waiting against the number of beds
ggplot(results_df, aes(x = num_beds, y = percent_patients_waiting)) +
  geom_point(size=1,
             alpha= 1) +
  geom_smooth(method = "gam") +
  theme_minimal() +
  labs(title = "Percent of Patients Waiting",
       x = "Number of Beds",
       y = "Percent of Patients Waiting") +
  geom_hline(yintercept = 5, linetype = "dashed", color = "red", size = 0.5)+
  scale_y_continuous(breaks = c(5,10,15,20,25,30,35))+
  scale_x_continuous(breaks = c(2,4,6,8,10,12,14,16,18,20,22,
                                24,26,28,30))






```

In the Figure 4, we see the relationship between the number of beds and the percent of patients waiting to be admitted into the ward. Please note that 5% rule for the percent of patients waiting, is an **average or overall target for the year**.

The Figure 4 shows that the optimal number of beds for a stroke ward with 350 patients annually would be 10 beds.

In the context of a stroke ward, rapid admission is critical for better patient outcome due to the time-sensitive nature of stroke treatment, hence striving for a 0% patient wait time would be considered ideal. In general, however, like all areas of healthcare, striving for a 0% patients wait time may not be feasible due to various operational constraints because factors such as the hospital's resources, policies, and the specific department or ward influence the threshold for percent of patients waiting at any given time.

It is important to highlight that many hospitals aim to follow guidelines that advocate for the rapid administration of treatment once a patient arrives at the hospital. For example in the US, The American Heart Association/American Stroke Association (AHA/ASA) guidelines recommend a door-to-needle time (the time from when a patient arrives at the hospital to when they receive intravenous thrombolytic therapy) of 60 minutes or less for at least 50% of acute ischemic stroke patients. @diercks2010prolonged @leifer2011metrics. In Australia guidelines regarding the stroke admissions are laid out by the Stroke Foundation -- Australia.

In Figure 5, we see that utilization percentages at $11$ beds for $350$ patients annually is less than $70 \%$. Typically $80 \% - 85 \%$ is considered an optimal utilization rate for wards; this threshold is often cited as a balance between efficiency (having enough patients to justify the beds used) and capacity (having enough free beds to accommodate influxes of patients). @aiken2002hospital

However, this figure can vary greatly depending on context. In the stroke ward a patient's length of stay is determined by the stroke severity and patient's medical history as well as their health condition at the time of the occurrence of the stroke. Some patients may need to stay for longer periods of time in the ward of up to 21 days to recover, in such instances, the bed remains occupied by a patient for a longer than expected period of time. Thus, it becomes critically important to ensure that there are enough beds available to accommodate patient influxes.

```{r figsix, fig.cap="Max. Queue length vs the number of beds", fig.align= 'center', fig.height=4, fig.width= 6, eval=TRUE, message=FALSE, warning=FALSE}

xintersection = 11
yintersection = 8
ggplot(results_df, aes(x = num_beds, y = max_queue_length)) +
  geom_point() +
  geom_smooth(method = "gam") +
  scale_x_continuous(breaks = seq(4, 20, by=2))+
  scale_y_continuous(breaks = seq(5, 155, by = 10))+
  # geom_vline(xintercept = 11, linetype="dashed", color = "steelblue", size = 0.5)+
  # geom_hline(yintercept = 8, linetype = "dashed", color = "red", size=0.5)+
  # geom_point(aes(x = xintersection, y = yintersection), color = "red", size = 1.5)+
  theme_minimal() +
  labs(title = "Maximum Queue Length vs. Number of Beds",
       x = "Number of Beds",
       y = "Maximum Queue Length")
```

**Maximum queue length** is yet another metric often considered when estimating the optimal number of beds, because this metric provides insight into the peak demand experienced by the system.

Often a high maximum queue length indicates a potential bottleneck in the system, while a lower maximum queue length suggests that the system is well-managed and has sufficient resources to handle the patient load, which can result in shorter waiting times and better patient experiences.

The maximum queue length in my simulation represents the highest number of patients waiting to be admitted at any point during the simulation period. In my simulation for $350$ patients per year and $11$ beds in the ward (optimal number of beds per utilization percentages), a maximum queue length of $15$ (as seen in Figure 6) means that at the peak of demand during the year, there were $15$ patients waiting to be admitted. However, it is important to be noted that this doesn't mean that $15$ patients will be waiting at all times. It's a snapshot of the worst-case scenario in terms of demand exceeding the number of available beds.

As discussed the 5% rule for the percent of patients waiting is an average or overall target for the year. It's possible for the percent of patients waiting to spike above this target at times (as seen in the max queue length), but on average across the year, the goal is to have less than 5% of patients waiting.

However, it's important to remember that this is the peak demand and does not necessarily reflect the average wait time across the year. This means that during our simulation there was a time in the year when up to 15 patients were waiting to be admitted (4.2% of the annual total patients), but this doesn't mean that 15 patients (4.2% of total patients) were always waiting.

```{r echo=FALSE}

stroke_sim_5 <- stroke_simulation(total_patients= total_patients, 
                                   arrival_rate= arrival_rate, 
                              bed_occupation_time = bed_occupation_time, 
                              stroke_level_prob= stroke_level_prob, 
                              num_beds= 5)

stroke_sim_8 <- stroke_simulation(total_patients= total_patients, 
                                   arrival_rate= arrival_rate, 
                              bed_occupation_time = bed_occupation_time, 
                              stroke_level_prob= stroke_level_prob, 
                              num_beds= 8)

stroke_sim_11 <- stroke_simulation(total_patients= total_patients, 
                                   arrival_rate= arrival_rate, 
                              bed_occupation_time = bed_occupation_time, 
                              stroke_level_prob= stroke_level_prob, 
                              num_beds= 11)


```

```{r}
# stroke_sim_25 <- data.frame(stroke_sim_25)
# 
# # stroke_sim_30 <- data.frame(stroke_sim_30)
# 
# stroke_sim_40 <- data.frame(stroke_sim_40)
# 
# 
# library(ggplot2)
# stroke_sim_25$length_of_stay <- as.numeric(stroke_sim_25$length_of_stay)
# 
# ggplot(stroke_sim_25, aes(y = length_of_stay)) +
#   geom_histogram(binwidth = 0.5, fill = "steelblue", alpha = 0.8) +
#   theme_minimal() +
#   labs(title = "Length of Stay Distribution",
#        x = "Length of Stay (days)",
#        y = "Frequency")
# 
# # stroke_sim_30$length_of_stay <- as.numeric(stroke_sim_30$length_of_stay)
# # 
# # ggplot(stroke_sim_30, aes(y= length_of_stay)) +
# #   geom_histogram(binwidh=0.5, fill="darkgrey", alpha=0.7 )+
# #   theme_light()+
# #   labs(title = "Length of Stay Distribution",
# #        x = "Length of Stay (days)",
# #        y = "Frequency")
# 
# stroke_sim_40$length_of_stay <- as.numeric(stroke_sim_40$length_of_stay)
# 
# stroke_sim_40 <- data.frame(stroke_sim_40)
# ggplot(stroke_sim_40, aes(y= length_of_stay)) +
#   geom_histogram(binwidh=0.5, fill="lightblue", alpha=0.7 )+
#   theme_light()+
#   labs(title = "Length of Stay Distribution",
#        x = "Length of Stay (days)",
#        y = "Frequency")
```

```{r}
ggplot(results_df, aes(x = num_beds, y = utilization)) +
  geom_point() +
  geom_smooth(method = "gam") +
  scale_x_continuous(breaks = seq(4, 35, by=2))+
  scale_y_continuous(breaks = seq(5, 100, by = 10))+
  #geom_vline(xintercept = 11, linetype="dashed", color = "steelblue", size = 0.5)+
  #geom_hline(yintercept = 8, linetype = "dashed", color = "red", size=0.5)+
  #geom_point(aes(x = xintersection, y = yintersection), color = "red", size = 1.5)+
  theme_minimal() +
  labs(title = "Utilization % vs. Number of Beds",
       x = "Number of Beds",
       y = "Utilization Percentage")
```

#### Sensitivity Analysis

```{r}
# Function to run simulation
run_simulation_sa <- function(params, num_simulations) {
  num_bed_range <- seq(5,20, by=1)
  
  performance_metrics_list <- lapply(1:num_simulations, function(simulation) {
    lapply(num_bed_range, function(num_beds) {
      stroke_sim <- stroke_simulation(total_patients =  params$total_patients,
                                      arrival_rate = params$arrival_rate,
                                      bed_occupation_time = params$bed_occupation_time,
                                      stroke_level_prob = params$stroke_level_prob,
                                      num_beds = num_beds)
      
      # Calculate only the desired metrics
      num_beds <- length(stroke_sim$beds)

      occupied_beds <- sum(stroke_sim$beds > 0)
      utilization <- occupied_beds / num_beds

      num_patients_queue <- length(stroke_sim$queue)

      proportion_patients_waiting <- num_patients_queue / total_patients
      percent_patients_waiting <- proportion_patients_waiting * 100

      max_queue_length <- length(stroke_sim$queue)
      
      # Return only the desired metrics
      performance_metrics_month <- data.frame(num_beds = num_beds,
                                              utilization = utilization,
                                              percent_patients_waiting = percent_patients_waiting,
                                              max_queue_length = max_queue_length)
      
      return(performance_metrics_month)
    })
  })
  
  # Collapse the list of data frames into one data frame
  performance_metrics_df <- do.call(rbind, unlist(performance_metrics_list, recursive = FALSE))
  
  return(performance_metrics_df)
}


# Initialize a data frame to store results
# results_df_sa <- data.frame()

# Original parameters
params <- list(arrival_rate = 1,
               bed_occupation_time = bed_occupation_time,
               stroke_level_prob = stroke_level_prob,
               total_patients = total_patients)
# Define the factors by which we'll vary the parameters
factors <- c(1.5, 2.5, 3.5, 4.5 )

# Initialize an empty list to store results
results <- list()

# Vary parameters
for (param in names(params)) {
  for (factor in factors) {
    params_adjusted <- params
    if (param == 'bed_occupation_time') {
      params_adjusted[[param]] <- unlist(lapply(params[[param]], function(x) x * factor))
    } else {
      params_adjusted[[param]] <- params[[param]] * factor
    }
    # Run simulation
    output <- run_simulation_sa(params_adjusted, num_simulations = 120)
    
    # Store results
    results[[paste(param, factor, sep = "_")]] <- output
  }
}

# Compute summary statistics
for (param in names(params)) {
  for (factor in factors) {
    print(paste("Summary for", param, "multiplied by", factor))
    print(summary(results[[paste(param, factor, sep = "_")]][,c("utilization", "percent_patients_waiting", "max_queue_length")]))
  }
}
```

Based on the sensitivity analysis, the healthcare system's efficiency and capacity were tested under increased pressures on multiple parameters. The variables tested include arrival_rate, bed_occupation_time, stroke_level_prob, and total_patients, with each variable multiplied by a factor of $1.5$, $2.5$, $3.5$, and $4.5$, respectively.

For the arrival_rate, as the multiplying factor increased, we observed a consistent rise in all three performance metrics.

-   With a 1.5 multiplier, the mean utilization was 0.75 ( $76 \%$), increasing steadily to 0.978 ( $98 \%$) at a 4.5 multiplier. This indicates that as more patients arrive, the beds become increasingly utilized. The waiting percentage of patients also increased from a mean of $15.6 \%$ to 57.50, while the max_queue_length ballooned from 54.89 to 201.2 patients.

-   Similar trends were observed with bed_occupation_time. With increased occupation time, there was a significant rise in utilization, waiting patients, and queue length. This implies that prolonged occupation times exert considerable pressure on the system, leaving fewer resources for new patients and creating long queues.

-   On the other hand, changes in *stroke_level_prob,* did not have a significant impact on the performance metrics. The utilization, percentage of patients waiting, and max queue length remained relatively consistent across all multiplying factors, indicating that the stroke severity level distribution does not significantly affect the system's capacity and efficiency.

-   Lastly, changes in total_patients exhibited similar trends to arrival_rate and bed_occupation_time, with all measured values increasing alongside the multiplier. However, these changes were more **drastic**, indicating that an increase in the total number of patients significantly strains the bed resource. For instance, the mean max_queue_length skyrocketed from 39.4 at a 1.5 multiplier to 119.6 at a 4.5 multiplier, revealing the system's limitations in handling a large volume of patients.

In conclusion, these findings illustrate the healthcare system's vulnerability to high patient arrival rates, extended bed occupation times, and a large total number of patients. While stroke severity level changes do not significantly affect system performance, strategic improvements should focus on efficient patient handling and reducing bed occupation times to enhance capacity and minimize patient waiting times. Future studies could further explore potential optimization strategies, taking into consideration real-world constraints and potential trade-offs.

### Conclusion

In summary, remarkably, it was observed that the complex interplay between the number of hospital beds, annual patient influx, and bed occupation duration, results in substantial effects on both patient wait times and bed utilization ratios.

The ability of our model to imitate various availability of hospital beds was instrumental in evaluating their impact on patient waiting periods and bed utilization rates.

The implications of this model in practical scenarios are profound. It offers an intuitive tool to policy makers and hospital management for efficient resource strategy formulation, based on live data and fluctuating patient load.

More importantly, the model is inherently connected to the core objective of our study/project, which is to enhance the allocation of hospital beds for stroke patients, focusing on minimizing patient waiting durations and optimizing bed utilization rates.

Despite its advantages, our model has its inherent limitations.

It oversimplifies a complex reality, based on assumptions about patient arrival times, stroke severity distributions, and bed occupancy durations. The actual situation may stray from these assumptions. Instances like sudden patient surges aren't factored into the current model. Also, the model overlooks other potential bottlenecks in stroke patient care, like the availability of healthcare staff or medical apparatus.

**Future enhancements** to this model could include its extension to a broader healthcare simulation, assimilating other elements of hospital resources and facilities. Further, future iterations could investigate the integration of more advanced machine learning methodologies for predicting patient loads and stroke severity distributions, thereby enhancing the decision-making process.

To encapsulate, our stroke simulation model aids in understanding and addressing the complicated task of hospital beds for stroke patients. It paves the way towards more robust, dynamic, and inclusive healthcare simulation models. Despite its constraints, the model demonstrates significant potential to inform and impact hospital management strategies, eventually contributing to better patient care.

### References

### 
